{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QWdPNIqc6tnF",
    "outputId": "50b82cdc-095a-49fb-d0b4-dc0982d9f450"
   },
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8gPV5NMAFwS"
   },
   "source": [
    "Question 1: Extract Headlines from BBC News\n",
    "Goal: Extract top 5 headlines from https://www.bbc.com/news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fTl0jZBjAjEK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 BBC News Headlines:\n",
      "1. Gaza worse than hell on Earth, International Red Cross chief tells BBC as aid centres close for day\n",
      "2. South Korea's new president has a Trump-shaped crisis to avert\n",
      "3. The Indian pilot set for a historic space journey on Axiom-4\n",
      "4. Vanuatu looks into revoking Andrew Tate's golden passport\n",
      "5. Cologne evacuates 20,000 so WW2 bombs can be defused\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Send request to BBC News\n",
    "url = 'https://www.bbc.com/news'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 2: Parse the page content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Step 3: Find headline elements (common class used by BBC)\n",
    "headlines = soup.find_all('h2', limit=5)\n",
    "\n",
    "# Step 4: Print top 5 headlines\n",
    "print(\"Top 5 BBC News Headlines:\")\n",
    "for i, h in enumerate(headlines, 1):\n",
    "    print(f\"{i}. {h.text.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fTl0jZBjAjEK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Headlines\n",
      "1. South Korea's new president has a Trump-shaped crisis to avert\n",
      "2. The Indian pilot set for a historic space journey on Axiom-4\n",
      "3. Vanuatu looks into revoking Andrew Tate's golden passport\n",
      "4. Gaza now worse than hell on earth, humanitarian chief tells BBC\n",
      "5. South Korea's new president has a Trump-shaped crisis to avert\n"
     ]
    }
   ],
   "source": [
    "def c():\n",
    "    url = \"https://www.bbc.com/news\"  # Required to avoid 403 errors\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    print(\"Top Headlines\")\n",
    "    titles = soup.find_all('h2')[1:6]\n",
    "    for i, tag in enumerate(titles, 1):\n",
    "        print(f\"{i}. {tag.text}\")\n",
    "c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fTl0jZBjAjEK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Headlines\n",
      "1. South Korea's new president has a Trump-shaped crisis to avert\n",
      "2. The Indian pilot set for a historic space journey on Axiom-4\n",
      "3. Vanuatu looks into revoking Andrew Tate's golden passport\n",
      "4. Gaza now worse than hell on earth, humanitarian chief tells BBC\n",
      "5. South Korea's new president has a Trump-shaped crisis to avert\n"
     ]
    }
   ],
   "source": [
    "def c():\n",
    "    url = \"https://www.bbc.com/news\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}  # Required to avoid 403 errors\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    print(\"Top Headlines\")\n",
    "    titles = soup.find_all('h2')[1:6]\n",
    "    for i, tag in enumerate(titles, 1):\n",
    "        print(f\"{i}. {tag.text}\")\n",
    "c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHVwiUt2AKzi"
   },
   "source": [
    "Question 2: Get All Hyperlinks from a Website\n",
    "Goal: Extract and print all <a> tags (text + href) from https://example.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31x7shklAOUy",
    "outputId": "166b8587-8b21-42c9-ca01-504254929824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: More information... | Link: https://www.iana.org/domains/example\n"
     ]
    }
   ],
   "source": [
    "def extract_links():\n",
    "    url = \"https://example.com\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html')\n",
    "\n",
    "    links = soup.find_all('a')\n",
    "    for link in links:\n",
    "        text = link.get_text(strip=True)\n",
    "        href = link.get('href')\n",
    "        if href:\n",
    "            print(f\"Text: {text} | Link: {href}\")\n",
    "\n",
    "extract_links()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_AGysGGASsy"
   },
   "source": [
    "Question 3: Scrape Book Titles from books.toscrape.com\n",
    "Goal: Get titles of first 10 books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_n9Pv4qAYmC",
    "outputId": "89059902-b1ec-4214-d09c-fc56a917639a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. A Light in the Attic\n",
      "2. Tipping the Velvet\n",
      "3. Soumission\n",
      "4. Sharp Objects\n",
      "5. Sapiens: A Brief History of Humankind\n",
      "6. The Requiem Red\n",
      "7. The Dirty Little Secrets of Getting Your Dream Job\n",
      "8. The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull\n",
      "9. The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics\n",
      "10. The Black Maria\n"
     ]
    }
   ],
   "source": [
    "def scrape_book_titles():\n",
    "    url = \"http://books.toscrape.com\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html')\n",
    "\n",
    "    books = soup.find_all('h3')[:10]\n",
    "    for i, book in enumerate(books, 1):\n",
    "        title = book.a['title']\n",
    "        print(f\"{i}. {title}\")\n",
    "\n",
    "scrape_book_titles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFylFJU6AZ-6"
   },
   "source": [
    "Question 4: Extract Quotes and Authors\n",
    "Goal: Get 5 quotes and their authors from http://quotes.toscrape.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xj7xdluHAdci",
    "outputId": "6bc33298-3d35-4ab4-fff6-bf293f6879c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.” — Albert Einstein\n",
      "2. “It is our choices, Harry, that show what we truly are, far more than our abilities.” — J.K. Rowling\n",
      "3. “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.” — Albert Einstein\n",
      "4. “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.” — Jane Austen\n",
      "5. “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.” — Marilyn Monroe\n"
     ]
    }
   ],
   "source": [
    "def scrape_quotes():\n",
    "    url = \"http://quotes.toscrape.com\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    quotes = soup.find_all('div', class_='quote')[:5]\n",
    "    for i, quote in enumerate(quotes, 1):\n",
    "        text = quote.find('span', class_='text').get_text(strip=True)\n",
    "        author = quote.find('small', class_='author').get_text(strip=True)\n",
    "        print(f\"{i}. {text} — {author}\")\n",
    "\n",
    "scrape_quotes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66ZiN3UYAhZq"
   },
   "source": [
    "Question 5: Scrape IMDb Top 10 Movies\n",
    "Goal: Extract top 10 movie titles from IMDb Top 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fTl0jZBjAjEK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 1. The Shawshank Redemption\n",
      "2. 2. The Godfather\n",
      "3. 3. The Dark Knight\n",
      "4. 4. The Godfather: Part II\n",
      "5. 5. 12 Angry Men\n",
      "6. 6. The Lord of the Rings: The Return of the King\n",
      "7. 7. Schindler's List\n",
      "8. 8. Pulp Fiction\n",
      "9. 9. The Lord of the Rings: The Fellowship of the Ring\n",
      "10. 10. Il Buono, Il Brutto, Il Cattivo\n"
     ]
    }
   ],
   "source": [
    "def scrape_imdb_top_movies():\n",
    "    url = \"https://www.imdb.com/chart/top\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}  # Required to avoid 403 errors\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    titles = soup.find_all('h3')[1:11]\n",
    "    for i, tag in enumerate(titles, 1):\n",
    "        print(f\"{i}. {tag.text}\")\n",
    "\n",
    "scrape_imdb_top_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
